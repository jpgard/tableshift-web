<!DOCTYPE html>
<html lang="en">
<head>
          <title>The TableShift Benchmark - Quickstart</title>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <link href="https://jpgard.github.io/tableshift-web/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="The TableShift Benchmark Full Atom Feed" />


</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="../">The TableShift Benchmark</a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="../pages/benchmark-datasets.html">Benchmark Datasets</a></li>
            <li><a href="../">TableShift Home</a></li>
            <li class="active"><a href="../pages/quickstart.html">Quickstart</a></li>
        </ul></nav><!-- /#menu -->
    <h1>Quickstart</h1>
    

    <ol>
<li>Environment setup</li>
</ol>
<p>We recommend using the Conda environment in the TableShift github repo. You can create an environment with all dependencies required via</p>
<div class="highlight"><pre><span></span><code>conda env create -f environment.yml
</code></pre></div>

<p>where <code>environment.yml</code> can be changed to point to the location of the file at the root of the TableShift git repo.</p>
<p>Once the conda environment is created, activate it with</p>
<div class="highlight"><pre><span></span><code>conda activate tableshift
</code></pre></div>

<ol>
<li>Train model</li>
</ol>
<p>TableShift includes implementations of 19 different models (described in the paper and in detail  <a href="">here</a>). To train a model on a publicly-available dataset, you can you the example script provided in the <code>examples</code> directory:</p>
<div class="highlight"><pre><span></span><code>python examples/run_expt.py --experiment diabetes_readmission --model xgb
</code></pre></div>

<p>That's it! If you would like to run distributed hyperparameter tuning with Ray, you can run</p>
<div class="highlight"><pre><span></span><code>ulimit -u 127590 &amp;&amp; python scripts/ray_train.py \
    --experiment adult \
    --num_samples 2 \
    --num_workers 1 \
    --cpu_per_worker 4 \
    --use_cached \
    --models xgb
</code></pre></div>

<p>*<em>please note that Ray can require careful tuning based on your system resources for optimal performance. For more information, check the <a href="https://docs.ray.io/en/latest/tune/index.html">Ray Tune documentation</a>.</em></p>

        <p>
        Last updated: Fri 02 June 2023
        </p>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>